# K8sé›†ç¾¤æ‰«æç³»ç»Ÿç”¨æˆ·æŒ‡å—

## 1. æ‰«æç³»ç»Ÿä¾èµ–å…³ç³»

### 1.1 scanæ˜¯å¦ä¾èµ–main.pyï¼Ÿ

**ç­”æ¡ˆï¼šä¸ä¾èµ–**ã€‚æ‰«æç³»ç»Ÿå¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œæœ‰ä»¥ä¸‹å‡ ç§å¯åŠ¨æ–¹å¼ï¼š

1. **ç‹¬ç«‹æ‰«ææ¼”ç¤º**ï¼š`src/scanner/scanner_demo.py`
2. **é›†æˆæµ‹è¯•è¿è¡Œ**ï¼š`test/test_scan_integration.py`
3. **å•å…ƒæµ‹è¯•è¿è¡Œ**ï¼š`test/test_cluster_scanner.py`

### 1.2 æ‰«æç³»ç»Ÿæ¶æ„

```
æ‰«æç³»ç»Ÿç‹¬ç«‹ç»„ä»¶:
â”œâ”€â”€ ScanCoordinator (æ‰«æåè°ƒå™¨)
â”œâ”€â”€ ClusterScanner (é›†ç¾¤æ‰«æå™¨)
â”œâ”€â”€ ResourceParser (èµ„æºè§£æå™¨)
â”œâ”€â”€ CacheManager (ç¼“å­˜ç®¡ç†å™¨)
â””â”€â”€ MCPToolLoader (å·¥å…·åŠ è½½å™¨)

main.py åªæ˜¯ä¸€ä¸ªå¯é€‰çš„é›†æˆå…¥å£ç‚¹
```

## 2. å¦‚ä½•å¯åŠ¨æ‰«æ

### 2.1 æ–¹æ³•ä¸€ï¼šä½¿ç”¨æ‰«ææ¼”ç¤ºç¨‹åºï¼ˆæ¨èï¼‰

```bash
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd /home/user/workspace/use-k8s-mcp

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH=$PWD/src:$PYTHONPATH

# è¿è¡Œæ‰«ææ¼”ç¤º
uv run python src/scanner/scanner_demo.py
```

### 2.2 æ–¹æ³•äºŒï¼šä½¿ç”¨é›†æˆæµ‹è¯•

```bash
# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆåŒ…å«æ‰«æåŠŸèƒ½éªŒè¯ï¼‰
uv run python test/test_scan_integration.py
```

### 2.3 æ–¹æ³•ä¸‰ï¼šç¼–ç¨‹æ–¹å¼å¯åŠ¨

åˆ›å»ºè‡ªå®šä¹‰æ‰«æè„šæœ¬ï¼š

```python
# custom_scan.py
import asyncio
import os
from dotenv import load_dotenv
from mcp_use import MCPClient

# æ·»åŠ srcåˆ°è·¯å¾„
import sys
sys.path.insert(0, 'src')

from src.scanner import ClusterScanner, ScanCoordinator, ResourceParser
from src.cache import CacheManager
from src.mcp_tools import MCPToolLoader

async def run_custom_scan():
    """è‡ªå®šä¹‰æ‰«æè¿è¡Œ"""
    load_dotenv()
    
    # 1. åˆ›å»ºMCPå®¢æˆ·ç«¯
    config = {
        "mcpServers": {
            os.getenv("MCP_SERVER_NAME", "k8s"): {
                "type": os.getenv("MCP_SERVER_TYPE", "stdio"),
                "url": os.getenv("MCP_SERVER_URL", "")
            }
        }
    }
    mcp_client = MCPClient.from_dict(config)
    
    # 2. åˆå§‹åŒ–ç»„ä»¶
    cache_manager = CacheManager()
    tool_loader = MCPToolLoader(cache_manager)
    cluster_scanner = ClusterScanner(mcp_client, tool_loader)
    resource_parser = ResourceParser()
    
    scan_coordinator = ScanCoordinator(
        cluster_scanner=cluster_scanner,
        resource_parser=resource_parser,
        cache_manager=cache_manager,
        static_ttl=1800,  # 30åˆ†é’Ÿ
        dynamic_ttl=300   # 5åˆ†é’Ÿ
    )
    
    # 3. æ‰§è¡Œæ‰«æ
    result = await scan_coordinator.scan_cluster_full(
        cluster_name="my-cluster",
        include_static=True,
        include_dynamic=True
    )
    
    print(f"æ‰«æå®Œæˆ: {result}")

if __name__ == '__main__':
    asyncio.run(run_custom_scan())
```

## 3. éªŒè¯æ‰«æå·²ç»ç”Ÿæ•ˆ

### 3.1 æ£€æŸ¥æ‰«æçŠ¶æ€

```python
# æ£€æŸ¥æ‰«æçŠ¶æ€çš„æ–¹æ³•
async def check_scan_status():
    # 1. å¥åº·æ£€æŸ¥
    health = await scan_coordinator.health_check()
    print(f"ç³»ç»ŸçŠ¶æ€: {health['status']}")
    print(f"ç»„ä»¶çŠ¶æ€: {health['components']}")
    
    # 2. è·å–æ‰«æå†å²
    history = await scan_coordinator.get_scan_history("my-cluster", limit=5)
    for record in history:
        print(f"è¡¨: {record['table_name']}, çŠ¶æ€: {record['scan_status']}")
        print(f"æœ€åæ‰«æ: {record['last_scan_at']}")
    
    # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = scan_coordinator.get_coordinator_stats()
    print(f"æ‰«æä¼šè¯: {stats['scan_sessions']}")
    print(f"æˆåŠŸæ‰«æ: {stats['successful_scans']}")
    print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
```

### 3.2 éªŒè¯æ‰«æç»“æœ

æ‰«ææˆåŠŸçš„æ ‡å¿—ï¼š

```bash
# è¿è¡Œæ‰«ææ¼”ç¤ºåï¼ŒæŸ¥çœ‹è¾“å‡º
âœ… é›†ç¾¤æ‰«æå®Œæˆ!
ğŸ“Š æ‰«æç»Ÿè®¡:
   - é›†ç¾¤åç§°: demo-cluster
   - æ‰«ææ—¶é•¿: 2.34ç§’
   - é™æ€èµ„æº: 5 ä¸ª
     * clusters: 1
     * namespaces: 2
     * nodes: 2
   - åŠ¨æ€èµ„æº: 15 ä¸ª
     * pods: 10
     * services: 5
   - æ€»èµ„æºæ•°: 20
```

## 4. å¦‚ä½•æŸ¥çœ‹æ•°æ®å·²ç»è¿›å…¥æ•°æ®åº“

### 4.1 ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨æŸ¥è¯¢

```python
# æŸ¥è¯¢ç¼“å­˜æ•°æ®çš„æ–¹æ³•
def check_cached_data():
    cache_manager = CacheManager()
    
    # 1. æŸ¥è¯¢é›†ç¾¤ä¿¡æ¯
    clusters = cache_manager.list_records('clusters')
    print(f"ç¼“å­˜çš„é›†ç¾¤: {len(clusters)} ä¸ª")
    for cluster in clusters:
        print(f"  - {cluster.name}: {cluster.version}")
    
    # 2. æŸ¥è¯¢å‘½åç©ºé—´
    namespaces = cache_manager.list_records('namespaces')
    print(f"ç¼“å­˜çš„å‘½åç©ºé—´: {len(namespaces)} ä¸ª")
    
    # 3. æŸ¥è¯¢Pod
    pods = cache_manager.list_records('pods')
    print(f"ç¼“å­˜çš„Pod: {len(pods)} ä¸ª")
    
    # 4. æŸ¥è¯¢ç¼“å­˜å…ƒæ•°æ®
    metadata = cache_manager.list_records('cache_metadata')
    print(f"ç¼“å­˜å…ƒæ•°æ®: {len(metadata)} æ¡")
    for meta in metadata:
        print(f"  - è¡¨: {meta.table_name}, çŠ¶æ€: {meta.scan_status}")
```

### 4.2 ç›´æ¥æŸ¥è¯¢SQLiteæ•°æ®åº“

```bash
# æŸ¥çœ‹æ•°æ®åº“æ–‡ä»¶ä½ç½®
echo $CACHE_DB_PATH
# æˆ–é»˜è®¤ä½ç½®: ./data/k8s_cache.db

# ä½¿ç”¨sqlite3å‘½ä»¤è¡Œå·¥å…·
sqlite3 ./data/k8s_cache.db

# æŸ¥çœ‹æ‰€æœ‰è¡¨
.tables

# æŸ¥çœ‹é›†ç¾¤æ•°æ®
SELECT name, version, node_count, created_at FROM clusters;

# æŸ¥çœ‹å‘½åç©ºé—´æ•°æ®
SELECT cluster_name, name, status FROM namespaces;

# æŸ¥çœ‹Podæ•°æ®
SELECT cluster_name, namespace, name, phase, node_name FROM pods LIMIT 10;

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
SELECT 
    table_name,
    cluster_name,
    record_count,
    last_scan_at,
    scan_status
FROM cache_metadata;

# æ£€æŸ¥TTLçŠ¶æ€
SELECT 
    'clusters' as table_name,
    COUNT(*) as total,
    COUNT(CASE WHEN ttl_expires_at < datetime('now') THEN 1 END) as expired
FROM clusters
UNION ALL
SELECT 
    'pods' as table_name,
    COUNT(*) as total,
    COUNT(CASE WHEN ttl_expires_at < datetime('now') THEN 1 END) as expired
FROM pods;
```

### 4.3 ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢è„šæœ¬

åˆ›å»ºæŸ¥è¯¢è„šæœ¬ï¼š

```python
# db_query.py
import sqlite3
import os
from datetime import datetime

def query_database():
    """æŸ¥è¯¢æ•°æ®åº“å†…å®¹"""
    db_path = os.getenv('CACHE_DB_PATH', './data/k8s_cache.db')
    
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row  # ä½¿ç»“æœå¯ä»¥æŒ‰åˆ—åè®¿é—®
        cursor = conn.cursor()
        
        print("=" * 60)
        print("ğŸ“Š K8sç¼“å­˜æ•°æ®åº“æŸ¥è¯¢ç»“æœ")
        print("=" * 60)
        
        # 1. æŸ¥çœ‹è¡¨ç»Ÿè®¡
        tables = ['clusters', 'namespaces', 'nodes', 'pods', 'services']
        for table in tables:
            cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
            count = cursor.fetchone()['count']
            print(f"ğŸ“‹ {table}: {count} æ¡è®°å½•")
        
        print("\n" + "-" * 40)
        
        # 2. æŸ¥çœ‹æœ€æ–°çš„é›†ç¾¤ä¿¡æ¯
        cursor.execute("""
            SELECT name, version, node_count, created_at 
            FROM clusters 
            ORDER BY created_at DESC 
            LIMIT 5
        """)
        
        clusters = cursor.fetchall()
        if clusters:
            print("ğŸ¢ æœ€æ–°é›†ç¾¤ä¿¡æ¯:")
            for cluster in clusters:
                print(f"  - {cluster['name']}: v{cluster['version']} ({cluster['node_count']} èŠ‚ç‚¹)")
        
        # 3. æŸ¥çœ‹æ‰«æçŠ¶æ€
        cursor.execute("""
            SELECT table_name, cluster_name, scan_status, last_scan_at
            FROM cache_metadata
            ORDER BY last_scan_at DESC
            LIMIT 10
        """)
        
        metadata = cursor.fetchall()
        if metadata:
            print("\nğŸ“ˆ æœ€è¿‘æ‰«æçŠ¶æ€:")
            for meta in metadata:
                print(f"  - {meta['table_name']} ({meta['cluster_name']}): {meta['scan_status']}")
                print(f"    æœ€åæ‰«æ: {meta['last_scan_at']}")
        
        conn.close()
        print("\nâœ… æ•°æ®åº“æŸ¥è¯¢å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")

if __name__ == '__main__':
    query_database()
```

è¿è¡ŒæŸ¥è¯¢è„šæœ¬ï¼š

```bash
uv run python db_query.py
```

## 5. ç¯å¢ƒé…ç½®è¦æ±‚

### 5.1 å¿…éœ€çš„ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶é…ç½®
# MCPæœåŠ¡å™¨é…ç½®
MCP_SERVER_URL=stdio:///path/to/k8s-mcp
MCP_SERVER_TYPE=stdio
MCP_SERVER_NAME=k8s-mcp

# ç¼“å­˜é…ç½®
CACHE_DB_PATH=./data/k8s_cache.db
CACHE_STATIC_TTL=1800
CACHE_DYNAMIC_TTL=300

# æ‰«æé…ç½®
SCANNER_STATIC_INTERVAL=1800
SCANNER_DYNAMIC_INTERVAL=300
SCANNER_TIMEOUT=120
```

### 5.2 éªŒè¯é…ç½®

```python
# éªŒè¯é…ç½®çš„è„šæœ¬
def validate_scan_config():
    """éªŒè¯æ‰«æé…ç½®"""
    required_vars = [
        'MCP_SERVER_URL', 'MCP_SERVER_TYPE', 'MCP_SERVER_NAME',
        'CACHE_DB_PATH', 'CACHE_STATIC_TTL', 'CACHE_DYNAMIC_TTL'
    ]
    
    missing = []
    for var in required_vars:
        if not os.getenv(var):
            missing.append(var)
    
    if missing:
        print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing)}")
        return False
    
    print("âœ… æ‰«æé…ç½®éªŒè¯é€šè¿‡")
    return True
```

## 6. æ•…éšœæ’æŸ¥

### 6.1 å¸¸è§é—®é¢˜

**é—®é¢˜1ï¼šæ‰«æå¤±è´¥**
```
âŒ é›†ç¾¤æ‰«æå¤±è´¥: Tool k8s_list_pods failed after 3 attempts
```
**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥MCPæœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
- éªŒè¯MCP_SERVER_URLé…ç½®
- æ£€æŸ¥ç½‘ç»œè¿æ¥

**é—®é¢˜2ï¼šæ•°æ®åº“ä¸ºç©º**
```
ğŸ“‹ clusters: 0 æ¡è®°å½•
```
**è§£å†³æ–¹æ¡ˆï¼š**
- ç¡®è®¤æ‰«æå·²æˆåŠŸæ‰§è¡Œ
- æ£€æŸ¥TTLæ˜¯å¦è¿‡æœŸ
- éªŒè¯æ•°æ®åº“è·¯å¾„é…ç½®

**é—®é¢˜3ï¼šæƒé™é”™è¯¯**
```
âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: Permission denied
```
**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
- ç¡®è®¤CACHE_DB_PATHç›®å½•å­˜åœ¨
- éªŒè¯å†™å…¥æƒé™

### 6.2 è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
ls -la ./data/k8s_cache.db

# æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
sqlite3 ./data/k8s_cache.db "PRAGMA integrity_check;"

# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯
sqlite3 ./data/k8s_cache.db "
SELECT table_name, error_message, updated_at 
FROM cache_metadata 
WHERE scan_status = 'failed' 
ORDER BY updated_at DESC 
LIMIT 5;
"
```

---

**æ€»ç»“ï¼š**
1. æ‰«æç³»ç»Ÿä¸ä¾èµ–main.pyï¼Œå¯ç‹¬ç«‹è¿è¡Œ
2. ä½¿ç”¨`src/scanner/scanner_demo.py`æ˜¯æœ€ç®€å•çš„å¯åŠ¨æ–¹å¼
3. é€šè¿‡ç¼“å­˜ç®¡ç†å™¨æˆ–SQLiteå‘½ä»¤å¯ä»¥éªŒè¯æ•°æ®
4. é…ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡æ˜¯æˆåŠŸè¿è¡Œçš„å…³é”®
