"""
é›†ç¾¤æ‰«æå™¨æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é›†ç¾¤æ‰«æå™¨è¿›è¡ŒK8sèµ„æºæ‰«æ
"""

import asyncio
import os
import sys
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from mcp_use import MCPClient

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / 'src'))

# ä½¿ç”¨ç»å¯¹å¯¼å…¥
from src.scanner.cluster_scanner import ClusterScanner
from src.scanner.resource_parser import ResourceParser
from src.scanner.scan_coordinator import ScanCoordinator
from src.cache import CacheManager
from src.mcp_tools import MCPToolLoader
from src.llm_config import create_llm


async def demo_cluster_scanning():
    """æ¼”ç¤ºé›†ç¾¤æ‰«æåŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ” K8sé›†ç¾¤æ‰«æå™¨æ¼”ç¤º")
    print("=" * 60)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    try:
        # 1. åˆå§‹åŒ–ç»„ä»¶
        print("ğŸ”§ åˆå§‹åŒ–ç»„ä»¶...")
        
        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        config = {
            "mcpServers": {
                os.getenv("MCP_SERVER_NAME", "k8s"): {
                    "type": os.getenv("MCP_SERVER_TYPE", "stdio"),
                    "url": os.getenv("MCP_SERVER_URL", "")
                }
            }
        }
        mcp_client = MCPClient.from_dict(config)
        print("âœ… MCPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        cache_manager = CacheManager()
        print("âœ… ç¼“å­˜ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºå·¥å…·åŠ è½½å™¨
        tool_loader = MCPToolLoader(cache_manager)
        print("âœ… å·¥å…·åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ‰«æç»„ä»¶
        cluster_scanner = ClusterScanner(
            mcp_client=mcp_client,
            tool_loader=tool_loader,
            timeout=60,
            max_retries=2
        )
        
        resource_parser = ResourceParser()
        
        scan_coordinator = ScanCoordinator(
            cluster_scanner=cluster_scanner,
            resource_parser=resource_parser,
            cache_manager=cache_manager,
            static_ttl=1800,  # 30åˆ†é’Ÿ
            dynamic_ttl=300   # 5åˆ†é’Ÿ
        )
        print("âœ… æ‰«æç»„ä»¶åˆ›å»ºæˆåŠŸ")
        
        # 2. é¢„åŠ è½½MCPå·¥å…·
        print("\nğŸ› ï¸ é¢„åŠ è½½MCPå·¥å…·...")
        try:
            tools = await tool_loader.load_tools()
            print(f"âœ… æˆåŠŸåŠ è½½ {len(tools)} ä¸ªMCPå·¥å…·")
            
            # æ˜¾ç¤ºå¯ç”¨å·¥å…·
            for tool in tools[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {tool.name}: {tool.description}")
            if len(tools) > 5:
                print(f"   ... è¿˜æœ‰ {len(tools) - 5} ä¸ªå·¥å…·")
                
        except Exception as e:
            print(f"âš ï¸ å·¥å…·é¢„åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
        
        # 3. æ‰§è¡Œé›†ç¾¤æ‰«ææ¼”ç¤º
        print("\nğŸ” æ‰§è¡Œé›†ç¾¤æ‰«ææ¼”ç¤º...")
        cluster_name = "demo-cluster"
        
        try:
            # æ‰§è¡Œå®Œæ•´é›†ç¾¤æ‰«æ
            scan_result = await scan_coordinator.scan_cluster_full(
                cluster_name=cluster_name,
                include_static=True,
                include_dynamic=True
            )
            
            print("âœ… é›†ç¾¤æ‰«æå®Œæˆ!")
            print(f"ğŸ“Š æ‰«æç»Ÿè®¡:")
            print(f"   - é›†ç¾¤åç§°: {scan_result['cluster_name']}")
            print(f"   - æ‰«ææ—¶é•¿: {scan_result['scan_duration']:.2f}ç§’")
            
            # æ˜¾ç¤ºé™æ€èµ„æºç»Ÿè®¡
            static_stats = scan_result.get('static_resources', {})
            if static_stats.get('success'):
                static_data = static_stats.get('data', {})
                print(f"   - é™æ€èµ„æº: {sum(static_data.values())} ä¸ª")
                for resource_type, count in static_data.items():
                    print(f"     * {resource_type}: {count}")
            
            # æ˜¾ç¤ºåŠ¨æ€èµ„æºç»Ÿè®¡
            dynamic_stats = scan_result.get('dynamic_resources', {})
            if dynamic_stats.get('success'):
                dynamic_data = dynamic_stats.get('data', {})
                print(f"   - åŠ¨æ€èµ„æº: {sum(dynamic_data.values())} ä¸ª")
                for resource_type, count in dynamic_data.items():
                    print(f"     * {resource_type}: {count}")
            
            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            overall_stats = scan_result.get('statistics', {})
            print(f"   - æ€»èµ„æºæ•°: {overall_stats.get('total_resources', 0)}")
            
        except Exception as e:
            print(f"âŒ é›†ç¾¤æ‰«æå¤±è´¥: {e}")
            print("ğŸ’¡ è¿™å¯èƒ½æ˜¯å› ä¸ºMCPæœåŠ¡å™¨è¿æ¥é—®é¢˜æˆ–å·¥å…·ä¸å¯ç”¨")
        
        # 4. æ˜¾ç¤ºç»„ä»¶ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ ç»„ä»¶ç»Ÿè®¡ä¿¡æ¯:")
        
        # æ‰«æå™¨ç»Ÿè®¡
        scanner_stats = cluster_scanner.get_scan_stats()
        print(f"ğŸ” æ‰«æå™¨ç»Ÿè®¡:")
        print(f"   - æ‰«ææ¬¡æ•°: {scanner_stats['scan_count']}")
        print(f"   - é”™è¯¯æ¬¡æ•°: {scanner_stats['error_count']}")
        print(f"   - æˆåŠŸç‡: {scanner_stats['success_rate']:.1f}%")
        print(f"   - å¹³å‡æ‰«ææ—¶é—´: {scanner_stats['avg_scan_time']:.2f}ç§’")
        
        # è§£æå™¨ç»Ÿè®¡
        parser_stats = resource_parser.get_parsing_stats()
        print(f"ğŸ“ è§£æå™¨ç»Ÿè®¡:")
        print(f"   - è§£ææ¬¡æ•°: {parser_stats['parsed_count']}")
        print(f"   - é”™è¯¯æ¬¡æ•°: {parser_stats['error_count']}")
        print(f"   - æˆåŠŸç‡: {parser_stats['success_rate']:.1f}%")
        
        # åè°ƒå™¨ç»Ÿè®¡
        coordinator_stats = scan_coordinator.get_coordinator_stats()
        print(f"ğŸ¯ åè°ƒå™¨ç»Ÿè®¡:")
        print(f"   - æ‰«æä¼šè¯: {coordinator_stats['scan_sessions']}")
        print(f"   - æˆåŠŸæ‰«æ: {coordinator_stats['successful_scans']}")
        print(f"   - å¤±è´¥æ‰«æ: {coordinator_stats['failed_scans']}")
        print(f"   - æˆåŠŸç‡: {coordinator_stats['success_rate']:.1f}%")
        
        # 5. ç¼“å­˜æ•°æ®æŸ¥è¯¢æ¼”ç¤º
        print("\nğŸ’¾ ç¼“å­˜æ•°æ®æŸ¥è¯¢æ¼”ç¤º:")
        try:
            # æŸ¥è¯¢ç¼“å­˜çš„é›†ç¾¤ä¿¡æ¯
            clusters = cache_manager.list_records('clusters')
            print(f"ğŸ“‹ ç¼“å­˜çš„é›†ç¾¤: {len(clusters)} ä¸ª")
            
            # æŸ¥è¯¢ç¼“å­˜çš„å‘½åç©ºé—´
            namespaces = cache_manager.list_records('namespaces')
            print(f"ğŸ“‹ ç¼“å­˜çš„å‘½åç©ºé—´: {len(namespaces)} ä¸ª")
            
            # æŸ¥è¯¢ç¼“å­˜çš„Pod
            pods = cache_manager.list_records('pods')
            print(f"ğŸ“‹ ç¼“å­˜çš„Pod: {len(pods)} ä¸ª")
            
            # æŸ¥è¯¢ç¼“å­˜å…ƒæ•°æ®
            metadata_records = cache_manager.list_records('cache_metadata')
            print(f"ğŸ“‹ ç¼“å­˜å…ƒæ•°æ®: {len(metadata_records)} æ¡")
            
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜æŸ¥è¯¢å¤±è´¥: {e}")
        
        print("\n" + "=" * 60)
        print("âœ… é›†ç¾¤æ‰«æå™¨æ¼”ç¤ºå®Œæˆ!")
        print("ğŸ’¡ æ‰«æå™¨å·²æˆåŠŸå®ç°é™æ€å’ŒåŠ¨æ€èµ„æºçš„æ‰«æã€è§£æå’Œç¼“å­˜åŠŸèƒ½")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def demo_resource_parsing():
    """æ¼”ç¤ºèµ„æºè§£æåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“ èµ„æºè§£æå™¨æ¼”ç¤º")
    print("=" * 60)
    
    parser = ResourceParser()
    
    # æ¼”ç¤ºé›†ç¾¤ä¿¡æ¯è§£æ
    print("ğŸ¢ é›†ç¾¤ä¿¡æ¯è§£æ:")
    cluster_data = {
        'name': 'production-cluster',
        'version': 'v1.23.15',
        'server': 'https://prod-k8s.example.com:6443',
        'nodeCount': 5
    }
    
    cluster_info = parser.parse_cluster_info(cluster_data, 'production-cluster')
    print(f"   âœ… é›†ç¾¤: {cluster_info.name}")
    print(f"   ğŸ“Š ç‰ˆæœ¬: {cluster_info.version}")
    print(f"   ğŸ–¥ï¸  èŠ‚ç‚¹æ•°: {cluster_info.node_count}")
    
    # æ¼”ç¤ºå‘½åç©ºé—´è§£æ
    print("\nğŸ“ å‘½åç©ºé—´è§£æ:")
    namespace_data = [
        {
            'metadata': {'name': 'production', 'labels': {'env': 'prod'}},
            'status': {'phase': 'Active'}
        },
        {
            'metadata': {'name': 'staging', 'labels': {'env': 'staging'}},
            'status': {'phase': 'Active'}
        }
    ]
    
    namespaces = parser.parse_namespaces(namespace_data, 'production-cluster')
    for ns in namespaces:
        print(f"   âœ… å‘½åç©ºé—´: {ns.name} (çŠ¶æ€: {ns.status})")
    
    # æ¼”ç¤ºPodè§£æ
    print("\nğŸ³ Podè§£æ:")
    pod_data = [
        {
            'metadata': {
                'name': 'web-app-123',
                'namespace': 'production',
                'labels': {'app': 'web', 'version': 'v2.1'}
            },
            'status': {
                'phase': 'Running',
                'containerStatuses': [
                    {'name': 'web-container', 'ready': True, 'restartCount': 0}
                ]
            },
            'spec': {
                'nodeName': 'worker-node-1',
                'containers': [
                    {'name': 'web-container', 'image': 'nginx:1.21'}
                ]
            }
        }
    ]
    
    pods = parser.parse_pods(pod_data, 'production-cluster')
    for pod in pods:
        print(f"   âœ… Pod: {pod.name} (å‘½åç©ºé—´: {pod.namespace}, çŠ¶æ€: {pod.phase})")
        print(f"      ğŸ–¥ï¸  èŠ‚ç‚¹: {pod.node_name}")
        print(f"      ğŸ“¦ å®¹å™¨: {len(pod.containers)} ä¸ª")
    
    # æ˜¾ç¤ºè§£æç»Ÿè®¡
    stats = parser.get_parsing_stats()
    print(f"\nğŸ“Š è§£æç»Ÿè®¡:")
    print(f"   - è§£ææ€»æ•°: {stats['parsed_count']}")
    print(f"   - æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    
    print("âœ… èµ„æºè§£ææ¼”ç¤ºå®Œæˆ!")


if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨é›†ç¾¤æ‰«æå™¨æ¼”ç¤ºç¨‹åº")
    
    # è¿è¡Œèµ„æºè§£ææ¼”ç¤º
    demo_resource_parsing()
    
    # è¿è¡Œé›†ç¾¤æ‰«ææ¼”ç¤º
    asyncio.run(demo_cluster_scanning())
