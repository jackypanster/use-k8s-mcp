"""
çœŸå®K8sé›†ç¾¤æ‰«æåº”ç”¨ç¨‹åº
é›†æˆGemini 2.5 Flashå¤§æ¨¡å‹ï¼Œå¤„ç†çœŸå®çš„é›†ç¾¤æ•°æ®
"""

import asyncio
import json
import os
import re
import sys
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

from src.llm_config import create_llm
from src.cache.cache_manager import CacheManager
from src.cache.models import ClusterInfo, NamespaceInfo, NodeInfo, PodInfo, ServiceInfo
from src.scanner.exceptions import ScanError, ToolNotFoundError
from mcp_use import MCPClient, MCPAgent


class RealClusterScanApp:
    """çœŸå®K8sé›†ç¾¤æ‰«æåº”ç”¨ç¨‹åº - é›†æˆGemini 2.5 Flash"""
    
    def __init__(self):
        self.cache_manager = CacheManager()
        self.agent: Optional[MCPAgent] = None
        self.available_tools: Dict[str, Any] = {}
        self.scan_stats = {
            'total_scans': 0,
            'successful_scans': 0,
            'failed_scans': 0,
            'last_scan_time': None,
            'total_resources_scanned': 0,
            'clusters_discovered': 0
        }
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–æ‰«æåº”ç”¨"""
        try:
            print("ğŸ”§ åˆå§‹åŒ–çœŸå®K8sé›†ç¾¤æ‰«æåº”ç”¨...")
            print("ğŸ¤– é›†æˆGemini 2.5 Flashå¤§æ¨¡å‹...")
            
            # éªŒè¯ç¯å¢ƒé…ç½®
            self._validate_environment()
            
            # åˆå§‹åŒ–MCP Agent (ä½¿ç”¨Gemini 2.5 Flash)
            await self._initialize_agent()
            
            # åŠ è½½å¯ç”¨å·¥å…·
            await self._load_available_tools()
            
            print("âœ… çœŸå®æ‰«æåº”ç”¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            raise ScanError(f"çœŸå®æ‰«æåº”ç”¨åˆå§‹åŒ–å¤±è´¥: {e}") from e
    
    def _validate_environment(self) -> None:
        """éªŒè¯ç¯å¢ƒé…ç½®"""
        required_vars = ["MCP_SERVER_URL", "MCP_SERVER_TYPE", "MCP_SERVER_NAME"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            raise ScanError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        
        # éªŒè¯LLMé…ç½®
        llm_vars = ["OPENROUTER_API_KEY", "LLM_MODEL_NAME"]
        missing_llm_vars = [var for var in llm_vars if not os.getenv(var)]
        
        if missing_llm_vars:
            raise ScanError(f"ç¼ºå°‘LLMé…ç½®ç¯å¢ƒå˜é‡: {', '.join(missing_llm_vars)}")
    
    async def _initialize_agent(self) -> None:
        """åˆå§‹åŒ–MCP Agent (ä½¿ç”¨Gemini 2.5 Flash)"""
        try:
            config = {
                "mcpServers": {
                    os.getenv("MCP_SERVER_NAME"): {
                        "type": os.getenv("MCP_SERVER_TYPE"),
                        "url": os.getenv("MCP_SERVER_URL")
                    }
                }
            }
            
            mcp_client = MCPClient.from_dict(config)
            
            # ä½¿ç”¨Gemini 2.5 Flash
            llm = create_llm()
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {os.getenv('LLM_MODEL_NAME', 'google/gemini-2.5-flash')}")
            
            self.agent = MCPAgent(
                llm=llm,
                client=mcp_client,
                max_steps=15  # å¢åŠ æ­¥æ•°ä»¥å¤„ç†å¤æ‚çš„çœŸå®æ•°æ®
            )
            
        except Exception as e:
            raise ScanError(f"MCP Agentåˆå§‹åŒ–å¤±è´¥: {e}") from e
    
    async def _load_available_tools(self) -> None:
        """ä»æ•°æ®åº“åŠ è½½å¯ç”¨å·¥å…·"""
        try:
            tools = self.cache_manager.list_records('mcp_tools')
            self.available_tools = {tool.name: tool for tool in tools}
            print(f"ğŸ“‹ åŠ è½½äº† {len(self.available_tools)} ä¸ªå¯ç”¨å·¥å…·")
            
        except Exception as e:
            raise ScanError(f"å·¥å…·åŠ è½½å¤±è´¥: {e}") from e
    
    async def discover_all_clusters(self) -> List[Dict[str, Any]]:
        """å‘ç°æ‰€æœ‰å¯ç”¨çš„é›†ç¾¤"""
        if 'GET_CLUSTER_INFO' not in self.available_tools:
            raise ToolNotFoundError("GET_CLUSTER_INFOå·¥å…·ä¸å¯ç”¨")
        
        try:
            print("ğŸ” å‘ç°æ‰€æœ‰å¯ç”¨é›†ç¾¤...")
            
            result = await self.agent.run(
                "ä½¿ç”¨ GET_CLUSTER_INFO å·¥å…·è·å–æ‰€æœ‰å¯ç”¨çš„Kubernetesé›†ç¾¤ä¿¡æ¯ï¼Œ"
                "åŒ…æ‹¬é›†ç¾¤åç§°ã€æè¿°ã€ç«¯ç‚¹ã€ç‰ˆæœ¬å’ŒçŠ¶æ€ã€‚è¯·è¿”å›è¯¦ç»†çš„é›†ç¾¤åˆ—è¡¨ã€‚",
                max_steps=5
            )
            
            # è§£æé›†ç¾¤åˆ—è¡¨
            clusters = self._parse_cluster_list(result)
            
            print(f"âœ… å‘ç° {len(clusters)} ä¸ªé›†ç¾¤")
            for cluster in clusters:
                status_icon = "âœ…" if cluster.get('status') == 'Available' else "âŒ"
                print(f"   {status_icon} {cluster['name']}: {cluster.get('description', 'N/A')}")
            
            self.scan_stats['clusters_discovered'] = len(clusters)
            return clusters
            
        except Exception as e:
            print(f"âŒ é›†ç¾¤å‘ç°å¤±è´¥: {e}")
            return []
    
    def _parse_cluster_list(self, result: str) -> List[Dict[str, Any]]:
        """è§£æé›†ç¾¤åˆ—è¡¨ä¿¡æ¯"""
        clusters = []

        try:
            # å°è¯•ä»ç»“æœä¸­æå–é›†ç¾¤ä¿¡æ¯
            lines = result.split('\n')
            current_cluster = {}

            for line in lines:
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue

                # åŒ¹é…é›†ç¾¤åç§° (é€šå¸¸ä»¥**å¼€å¤´)
                cluster_name_match = re.search(r'\*\*([^*]+)\*\*', line)
                if cluster_name_match:
                    # ä¿å­˜å‰ä¸€ä¸ªé›†ç¾¤
                    if current_cluster and 'name' in current_cluster:
                        clusters.append(current_cluster)
                    current_cluster = {'name': cluster_name_match.group(1).strip()}
                    continue

                # åªæœ‰åœ¨æœ‰å½“å‰é›†ç¾¤çš„æƒ…å†µä¸‹æ‰è§£æå±æ€§
                if not current_cluster:
                    continue

                # åŒ¹é…æè¿°
                if 'Description:' in line:
                    desc_match = re.search(r'Description:\s*(.+)', line)
                    if desc_match:
                        current_cluster['description'] = desc_match.group(1).strip()

                # åŒ¹é…ç«¯ç‚¹
                elif 'Endpoint:' in line:
                    endpoint_match = re.search(r'Endpoint:\s*(.+)', line)
                    if endpoint_match:
                        current_cluster['endpoint'] = endpoint_match.group(1).strip()

                # åŒ¹é…ç‰ˆæœ¬
                elif 'Version:' in line:
                    version_match = re.search(r'Version:\s*(.+)', line)
                    if version_match:
                        current_cluster['version'] = version_match.group(1).strip()

                # åŒ¹é…çŠ¶æ€
                elif 'Status:' in line:
                    status_match = re.search(r'Status:\s*(.+)', line)
                    if status_match:
                        current_cluster['status'] = status_match.group(1).strip()

            # æ·»åŠ æœ€åä¸€ä¸ªé›†ç¾¤
            if current_cluster and 'name' in current_cluster:
                clusters.append(current_cluster)

            # è¿‡æ»¤æ‰æ— æ•ˆçš„é›†ç¾¤
            valid_clusters = []
            for cluster in clusters:
                if cluster.get('name') and len(cluster.get('name', '')) > 1:
                    valid_clusters.append(cluster)

            return valid_clusters

        except Exception as e:
            print(f"âš ï¸ é›†ç¾¤åˆ—è¡¨è§£æå¤±è´¥: {e}")
            return []
    
    async def scan_cluster_info(self, cluster_name: str) -> Optional[ClusterInfo]:
        """æ‰«ææŒ‡å®šé›†ç¾¤çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            print(f"ğŸ” æ‰«æé›†ç¾¤ä¿¡æ¯: {cluster_name}")
            
            result = await self.agent.run(
                f"ä½¿ç”¨ GET_CLUSTER_INFO å·¥å…·è·å–é›†ç¾¤ {cluster_name} çš„è¯¦ç»†ä¿¡æ¯ï¼Œ"
                f"åŒ…æ‹¬ç‰ˆæœ¬ã€ç«¯ç‚¹ã€çŠ¶æ€ç­‰ã€‚",
                max_steps=3
            )
            
            # ä½¿ç”¨Geminiè§£æçœŸå®ç»“æœ
            cluster_info = await self._parse_real_cluster_info(result, cluster_name)
            
            if cluster_info:
                # ä¿å­˜åˆ°ç¼“å­˜
                self.cache_manager.create_record('clusters', cluster_info)
                print(f"âœ… é›†ç¾¤ä¿¡æ¯å·²ç¼“å­˜: {cluster_info.name}")
                
            return cluster_info
            
        except Exception as e:
            print(f"âŒ é›†ç¾¤ä¿¡æ¯æ‰«æå¤±è´¥: {e}")
            return None
    
    async def _parse_real_cluster_info(self, result: str, cluster_name: str) -> Optional[ClusterInfo]:
        """ä½¿ç”¨Geminiè§£æçœŸå®çš„é›†ç¾¤ä¿¡æ¯"""
        try:
            # ä½¿ç”¨Geminiè§£æç»“æ„åŒ–æ•°æ®
            parse_result = await self.agent.run(
                f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–é›†ç¾¤ {cluster_name} çš„ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š\n"
                f"éœ€è¦æå–çš„å­—æ®µï¼šname, version, endpoint, status, description\n\n"
                f"åŸå§‹æ–‡æœ¬ï¼š\n{result}\n\n"
                f"è¯·è¿”å›æ ¼å¼ï¼š{{'name': '...', 'version': '...', 'endpoint': '...', 'status': '...', 'description': '...'}}",
                max_steps=2
            )
            
            # å°è¯•è§£æJSON
            try:
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{[^}]+\}', parse_result)
                if json_match:
                    cluster_data = json.loads(json_match.group())
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
                    cluster_data = self._extract_cluster_data_regex(result, cluster_name)
            except json.JSONDecodeError:
                cluster_data = self._extract_cluster_data_regex(result, cluster_name)
            
            if cluster_data:
                # ç¡®ä¿api_serverå­—æ®µä¸ä¸ºç©º
                api_server = cluster_data.get('endpoint') or cluster_data.get('api_server') or f'https://{cluster_name}:6443'

                return ClusterInfo(
                    name=cluster_data.get('name', cluster_name),
                    version=cluster_data.get('version', 'unknown'),
                    api_server=api_server,
                    node_count=0,  # éœ€è¦å•ç‹¬æŸ¥è¯¢
                    ttl_expires_at=datetime.utcnow() + timedelta(minutes=30)
                )
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ é›†ç¾¤ä¿¡æ¯è§£æå¤±è´¥: {e}")
            return None
    
    def _extract_cluster_data_regex(self, result: str, cluster_name: str) -> Dict[str, str]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é›†ç¾¤æ•°æ®"""
        cluster_data = {'name': cluster_name}
        
        # æå–ç‰ˆæœ¬
        version_match = re.search(r'Version:\s*([^\n\r]+)', result)
        if version_match:
            cluster_data['version'] = version_match.group(1).strip()
        
        # æå–ç«¯ç‚¹
        endpoint_match = re.search(r'Endpoint:\s*([^\n\r]+)', result)
        if endpoint_match:
            cluster_data['endpoint'] = endpoint_match.group(1).strip()
        
        # æå–çŠ¶æ€
        status_match = re.search(r'Status:\s*([^\n\r]+)', result)
        if status_match:
            cluster_data['status'] = status_match.group(1).strip()
        
        # æå–æè¿°
        desc_match = re.search(r'Description:\s*([^\n\r]+)', result)
        if desc_match:
            cluster_data['description'] = desc_match.group(1).strip()
        
        return cluster_data
    
    async def scan_namespaces(self, cluster_name: str) -> List[NamespaceInfo]:
        """æ‰«ææŒ‡å®šé›†ç¾¤çš„å‘½åç©ºé—´"""
        if 'LIST_NAMESPACES' not in self.available_tools:
            raise ToolNotFoundError("LIST_NAMESPACESå·¥å…·ä¸å¯ç”¨")
        
        try:
            print(f"ğŸ” æ‰«æå‘½åç©ºé—´: {cluster_name}")
            
            result = await self.agent.run(
                f"ä½¿ç”¨ LIST_NAMESPACES å·¥å…·åˆ—å‡ºé›†ç¾¤ {cluster_name} çš„æ‰€æœ‰å‘½åç©ºé—´ï¼Œ"
                f"åŒ…æ‹¬å‘½åç©ºé—´åç§°ã€çŠ¶æ€ã€æ ‡ç­¾ç­‰ä¿¡æ¯ã€‚",
                max_steps=3
            )
            
            # ä½¿ç”¨Geminiè§£æçœŸå®ç»“æœ
            namespaces = await self._parse_real_namespaces(result, cluster_name)
            
            # æ‰¹é‡ä¿å­˜åˆ°ç¼“å­˜
            for ns in namespaces:
                self.cache_manager.create_record('namespaces', ns)
            
            print(f"âœ… å‘½åç©ºé—´å·²ç¼“å­˜: {len(namespaces)} ä¸ª")
            return namespaces
            
        except Exception as e:
            print(f"âŒ å‘½åç©ºé—´æ‰«æå¤±è´¥: {e}")
            return []
    
    async def _parse_real_namespaces(self, result: str, cluster_name: str) -> List[NamespaceInfo]:
        """ä½¿ç”¨Geminiè§£æçœŸå®çš„å‘½åç©ºé—´ä¿¡æ¯"""
        try:
            # ä½¿ç”¨Geminiæå–å‘½åç©ºé—´åˆ—è¡¨
            parse_result = await self.agent.run(
                f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰å‘½åç©ºé—´çš„ä¿¡æ¯ï¼Œæ¯ä¸ªå‘½åç©ºé—´åŒ…å«nameå’Œstatuså­—æ®µï¼Œ"
                f"ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ï¼š[{{'name': '...', 'status': '...'}}]\n\n"
                f"åŸå§‹æ–‡æœ¬ï¼š\n{result}",
                max_steps=2
            )
            
            namespaces = []
            
            try:
                # å°è¯•è§£æJSON
                json_match = re.search(r'\[.*\]', parse_result, re.DOTALL)
                if json_match:
                    ns_data_list = json.loads(json_match.group())
                    for ns_data in ns_data_list:
                        ns_info = NamespaceInfo(
                            cluster_name=cluster_name,
                            name=ns_data.get('name', ''),
                            status=ns_data.get('status', 'Active'),
                            labels={},
                            annotations={},
                            ttl_expires_at=datetime.utcnow() + timedelta(minutes=30)
                        )
                        namespaces.append(ns_info)
            except (json.JSONDecodeError, KeyError):
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
                ns_names = re.findall(r'(\w+(?:-\w+)*)', result)
                for ns_name in set(ns_names):  # å»é‡
                    if len(ns_name) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                        ns_info = NamespaceInfo(
                            cluster_name=cluster_name,
                            name=ns_name,
                            status='Active',
                            labels={},
                            annotations={},
                            ttl_expires_at=datetime.utcnow() + timedelta(minutes=30)
                        )
                        namespaces.append(ns_info)
            
            return namespaces
            
        except Exception as e:
            print(f"âš ï¸ å‘½åç©ºé—´è§£æå¤±è´¥: {e}")
            return []
    
    async def scan_full_cluster(self, cluster_name: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„çœŸå®é›†ç¾¤æ‰«æ"""
        start_time = datetime.utcnow()
        scan_result = {
            'cluster_name': cluster_name,
            'scan_start_time': start_time,
            'success': False,
            'resources': {},
            'errors': []
        }
        
        try:
            print(f"\nğŸš€ å¼€å§‹çœŸå®é›†ç¾¤æ‰«æ: {cluster_name}")
            print("ğŸ¤– ä½¿ç”¨Gemini 2.5 Flashå¤„ç†çœŸå®æ•°æ®")
            print("=" * 50)
            
            # æ‰«æé›†ç¾¤ä¿¡æ¯
            print("ğŸ“Š æ‰«æé›†ç¾¤ä¿¡æ¯...")
            cluster_info = await self.scan_cluster_info(cluster_name)
            
            # æ‰«æå‘½åç©ºé—´
            print("ğŸ“ æ‰«æå‘½åç©ºé—´...")
            namespaces = await self.scan_namespaces(cluster_name)
            
            # æ±‡æ€»ç»“æœ
            scan_result['resources'] = {
                'cluster': cluster_info,
                'namespaces': namespaces,
                'nodes': [],  # å¯ä»¥æ‰©å±•
                'pods': [],   # å¯ä»¥æ‰©å±•
                'services': [] # å¯ä»¥æ‰©å±•
            }
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            total_resources = len(namespaces)
            if cluster_info:
                total_resources += 1
            
            scan_result['success'] = True
            scan_result['total_resources'] = total_resources
            scan_result['scan_duration'] = (datetime.utcnow() - start_time).total_seconds()
            
            # æ›´æ–°æ‰«æç»Ÿè®¡
            self.scan_stats['total_scans'] += 1
            self.scan_stats['successful_scans'] += 1
            self.scan_stats['last_scan_time'] = datetime.utcnow()
            self.scan_stats['total_resources_scanned'] += total_resources
            
            print(f"\nâœ… çœŸå®é›†ç¾¤æ‰«æå®Œæˆ!")
            print(f"ğŸ“Š æ‰«æç»Ÿè®¡:")
            print(f"   - é›†ç¾¤: {1 if cluster_info else 0}")
            print(f"   - å‘½åç©ºé—´: {len(namespaces)}")
            print(f"   - æ€»èµ„æº: {total_resources}")
            print(f"   - æ‰«æè€—æ—¶: {scan_result['scan_duration']:.2f} ç§’")
            
            return scan_result
            
        except Exception as e:
            scan_result['errors'].append(str(e))
            self.scan_stats['total_scans'] += 1
            self.scan_stats['failed_scans'] += 1
            print(f"âŒ çœŸå®é›†ç¾¤æ‰«æå¤±è´¥: {e}")
            return scan_result
    
    def get_scan_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰«æç»Ÿè®¡ä¿¡æ¯"""
        return self.scan_stats.copy()


async def main():
    """ä¸»å‡½æ•° - æµ‹è¯•çœŸå®é›†ç¾¤æ‰«æ"""
    load_dotenv()
    
    print("=" * 60)
    print("ğŸ” çœŸå®K8sé›†ç¾¤æ‰«æåº”ç”¨ç¨‹åº (Gemini 2.5 Flash)")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå¹¶åˆå§‹åŒ–çœŸå®æ‰«æåº”ç”¨
        app = RealClusterScanApp()
        await app.initialize()
        
        # å‘ç°æ‰€æœ‰é›†ç¾¤
        clusters = await app.discover_all_clusters()
        
        if clusters:
            # æ‰«æç¬¬ä¸€ä¸ªå¯ç”¨çš„é›†ç¾¤
            available_clusters = [c for c in clusters if c.get('status') == 'Available']
            if available_clusters:
                test_cluster = available_clusters[0]['name']
                print(f"\nğŸ¯ æµ‹è¯•æ‰«æé›†ç¾¤: {test_cluster}")
                result = await app.scan_full_cluster(test_cluster)
            else:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„é›†ç¾¤è¿›è¡Œæ‰«æ")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        stats = app.get_scan_statistics()
        print(f"\nğŸ“ˆ åº”ç”¨ç»Ÿè®¡:")
        print(f"   - å‘ç°é›†ç¾¤: {stats['clusters_discovered']}")
        print(f"   - æ€»æ‰«ææ¬¡æ•°: {stats['total_scans']}")
        print(f"   - æˆåŠŸæ‰«æ: {stats['successful_scans']}")
        print(f"   - å¤±è´¥æ‰«æ: {stats['failed_scans']}")
        print(f"   - æ€»èµ„æºæ•°: {stats['total_resources_scanned']}")
        
        print("\n" + "=" * 60)
        print("âœ… çœŸå®æ‰«æåº”ç”¨ç¨‹åºæ‰§è¡Œå®Œæˆ")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ åº”ç”¨ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    asyncio.run(main())
