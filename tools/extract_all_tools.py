#!/usr/bin/env python3
"""
K8s MCP å·¥å…·Schemaæå–è„šæœ¬
åŸºäº src/tool_discovery.pyï¼Œæå–æ‰€æœ‰55ä¸ªK8s MCPå·¥å…·çš„å®Œæ•´ä¿¡æ¯å¹¶ä¿å­˜ä¸ºJSONæ–‡ä»¶

æ ¸å¿ƒåŸåˆ™ï¼š
- ç»å¯¹ä¸è¦ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®
- ä¸¥æ ¼éµå¾ªå·¥å…·è¿”å›çš„åŸå§‹ç»“æœï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
- å•çº¿ç¨‹ä¸²è¡Œæ‰§è¡Œï¼Œfail-faståŸåˆ™
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"ğŸ”§ Pythonè·¯å¾„: {sys.path[0]}")

# å¯¼å…¥å·²éªŒè¯çš„å·¥å…·å‘ç°æ¨¡å—
from src.tool_discovery import get_tool_schema
from src.llm_config import create_llm
from dotenv import load_dotenv
from mcp_use import MCPAgent, MCPClient


async def extract_tool_list():
    """
    æå–æ‰€æœ‰K8s MCPå·¥å…·åˆ—è¡¨
    å¤ç”¨ src/tool_discovery.py ä¸­å·²éªŒè¯çš„é…ç½®
    """
    print(f"ğŸš€ begin extract_tool_list()")
    try:
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()

        # å¤ç”¨å·²éªŒè¯çš„ MCP é…ç½®ï¼ˆæ—  type å­—æ®µï¼‰
        server_name = os.getenv("MCP_SERVER_NAME")
        server_url = os.getenv("MCP_SERVER_URL")

        mcp_config = {
            "mcpServers": {
                server_name: {
                    "url": server_url
                }
            }
        }

        # åˆ›å»ºå·²éªŒè¯çš„ç»„ä»¶
        client = MCPClient.from_dict(mcp_config)
        llm = create_llm()
        agent = MCPAgent(llm=llm, client=client, max_steps=10)

        print(f"ğŸ”— MCPæœåŠ¡å™¨: {server_url}")

        # è·å–å·¥å…·åˆ—è¡¨ - ä½¿ç”¨ä¸ tool_discovery.py ç›¸åŒçš„ä¸¥æ ¼æŒ‡ä»¤
        tools_result = await agent.run(
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·åç§°ï¼Œåªè¿”å›å·¥å…·åç§°åˆ—è¡¨ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚
        ä¸¥æ ¼è¦æ±‚ï¼š
1. ç»å¯¹ä¸è¦ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®
2. ä¸¥æ ¼éµå¾ªå·¥å…·è¿”å›çš„åŸå§‹ç»“æœï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
3. åªå…è®¸å¯¹æ•°æ®è¿›è¡Œç»“æ„åŒ–è¾“å‡ºå’Œç¾åŒ–å±•ç¤º
4. ä¿ç•™æ‰€æœ‰å­—æ®µã€å€¼å’Œæ•°æ®ç»“æ„ï¼Œä¸å¾—çœç•¥ä»»ä½•ä¿¡æ¯
5. å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå¿…é¡»æ˜ç¡®æŠ¥å‘Šå¤±è´¥åŸå› ï¼Œä¸å¾—æä¾›ä»»ä½•æ¨¡æ‹Ÿæ•°æ®

ä½ çš„èŒè´£ä»…é™äºï¼šæ•°æ®æ ¼å¼åŒ–å’Œå¯è¯»æ€§ä¼˜åŒ–ï¼Œä¸¥ç¦ä»»ä½•å½¢å¼çš„æ•°æ®åˆ›é€ æˆ–ä¿®æ”¹ã€‚""",
            max_steps=5
        )

        print(f"ğŸ› ï¸ å·¥å…·åˆ—è¡¨åŸå§‹å“åº”:\n{tools_result}")
        print(f"ğŸ› ï¸ å·¥å…·åˆ—è¡¨åŸå§‹å“åº”é•¿åº¦: {len(tools_result)} chars")

        # è§£æå·¥å…·åˆ—è¡¨ - å¤ç”¨ tool_discovery.py çš„è§£æé€»è¾‘
        tool_names = []
        lines = tools_result.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('Thought:') and not line.startswith('Final Answer:'):
                # ç§»é™¤å¯èƒ½çš„åºå·å’Œç‰¹æ®Šå­—ç¬¦
                clean_line = line.replace('*', '').replace('-', '').replace('â€¢', '').strip()
                if clean_line and len(clean_line) > 2:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
                    tool_names.append(clean_line)

        print(f"ğŸ“Š è§£æå‡º: {tool_names}")
        print(f"ğŸ“Š è§£æå‡º {len(tool_names)} ä¸ªå·¥å…·åç§°")

        print(f"âœ… end extract_tool_list() - success (tools_count={len(tool_names)})")
        return tool_names
    except Exception as e:
        print(f"âŒ end extract_tool_list() - failed: {e}")
        raise


def save_tool_list(tools, output_dir):
    """
    ä¿å­˜å·¥å…·åˆ—è¡¨åˆ°JSONæ–‡ä»¶

    Args:
        tools: å·¥å…·åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    print(f"ğŸš€ begin save_tool_list(tools_count={len(tools)}, output_dir={output_dir})")
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # æ„å»ºå·¥å…·åˆ—è¡¨æ•°æ®ç»“æ„
        tool_list_data = {
            "total_count": len(tools),
            "tools": tools
        }

        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        output_file = output_dir / "tool_list.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(tool_list_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… å·¥å…·åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ“Š åŒ…å« {len(tools)} ä¸ªå·¥å…·åç§°")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_file.stat().st_size} bytes")

        print(f"âœ… end save_tool_list(tools_count={len(tools)}, output_dir={output_dir}) - success")
        return output_file
    except Exception as e:
        print(f"âŒ end save_tool_list(tools_count={len(tools)}, output_dir={output_dir}) - failed: {e}")
        raise


def load_completed_list(output_dir):
    """
    è¯»å–å·²å®Œæˆæ¸…å•æ–‡ä»¶

    Args:
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„

    Returns:
        list: å·²å®Œæˆçš„å·¥å…·åç§°åˆ—è¡¨
    """
    print(f"ğŸš€ begin load_completed_list(output_dir={output_dir})")
    try:
        output_dir = Path(output_dir)
        completed_file = output_dir / "completed_schemas.json"

        print(f"ğŸ“‹ è¯»å–å·²å®Œæˆæ¸…å•: {completed_file}")

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not completed_file.exists():
            print(f"   â„¹ï¸  æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨")
            print(f"âœ… end load_completed_list(output_dir={output_dir}) - success (count=0)")
            return []

        with open(completed_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        completed_tools = data.get('completed_tools', [])
        print(f"   âœ… å·²è¯»å– {len(completed_tools)} ä¸ªå·²å®Œæˆå·¥å…·")

        # æ˜¾ç¤ºå‰5ä¸ªå·²å®Œæˆçš„å·¥å…·
        if completed_tools:
            for i, tool in enumerate(completed_tools[:5]):
                print(f"      {i+1}. {tool}")
            if len(completed_tools) > 5:
                print(f"      ... è¿˜æœ‰ {len(completed_tools) - 5} ä¸ª")

        print(f"âœ… end load_completed_list(output_dir={output_dir}) - success (count={len(completed_tools)})")
        return completed_tools

    except json.JSONDecodeError as e:
        print(f"   âŒ æ¸…å•æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        print(f"âŒ end load_completed_list(output_dir={output_dir}) - failed: {e}")
        raise Exception(f"å·²å®Œæˆæ¸…å•æ–‡ä»¶æŸå: {completed_file}")
    except Exception as e:
        print(f"   âŒ è¯»å–æ¸…å•æ–‡ä»¶å¤±è´¥: {e}")
        print(f"âŒ end load_completed_list(output_dir={output_dir}) - failed: {e}")
        raise


def add_to_completed_list(tool_name, output_dir):
    """
    å‘å·²å®Œæˆæ¸…å•ä¸­æ·»åŠ æ–°å®Œæˆçš„å·¥å…·

    Args:
        tool_name: å·¥å…·åç§°
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    print(f"ğŸš€ begin add_to_completed_list(tool_name={tool_name}, output_dir={output_dir})")
    try:
        output_dir = Path(output_dir)
        completed_file = output_dir / "completed_schemas.json"

        print(f"ğŸ“ æ›´æ–°å·²å®Œæˆæ¸…å•: {tool_name}")

        # è¯»å–ç°æœ‰æ¸…å•
        completed_tools = load_completed_list(output_dir) if completed_file.exists() else []

        # é¿å…é‡å¤æ·»åŠ 
        if tool_name in completed_tools:
            print(f"   â„¹ï¸  å·¥å…·å·²åœ¨æ¸…å•ä¸­: {tool_name}")
            print(f"âœ… end add_to_completed_list(tool_name={tool_name}, output_dir={output_dir}) - success (already_exists)")
            return

        # æ·»åŠ æ–°å·¥å…·
        completed_tools.append(tool_name)

        # æ„å»ºæ¸…å•æ•°æ®ç»“æ„
        completed_data = {
            "completed_tools": completed_tools,
            "total_completed": len(completed_tools)
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(completed_file, 'w', encoding='utf-8') as f:
            json.dump(completed_data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… æ¸…å•å·²æ›´æ–°: {len(completed_tools)} ä¸ªå·¥å…·")
        print(f"   ğŸ“ æ–‡ä»¶å¤§å°: {completed_file.stat().st_size} bytes")

        print(f"âœ… end add_to_completed_list(tool_name={tool_name}, output_dir={output_dir}) - success (added)")

    except Exception as e:
        print(f"   âŒ æ›´æ–°æ¸…å•å¤±è´¥: {e}")
        print(f"âŒ end add_to_completed_list(tool_name={tool_name}, output_dir={output_dir}) - failed: {e}")
        raise Exception(f"æ— æ³•æ›´æ–°å·²å®Œæˆæ¸…å•: {e}")


async def save_tool_schema(tool_name, real_schema_data, output_dir):
    """
    ä¿å­˜å•ä¸ªå·¥å…·çš„schemaåˆ°JSONæ–‡ä»¶

    Args:
        tool_name: å·¥å…·åç§° (ä»å†…å­˜ä¸­çš„å·¥å…·åˆ—è¡¨ä¼ é€’)
        schema_data: schemaåŸå§‹æ•°æ® (ä» get_tool_schema() è·å–)
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„

    Returns:
        Path: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸš€ begin save_tool_schema(tool_name={tool_name}, output_dir={output_dir})")
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = Path(output_dir)
        tools_dir = output_dir / "tools"
        tools_dir.mkdir(parents=True, exist_ok=True)

        # æ„å»ºschemaæ•°æ®ç»“æ„ï¼Œä¿æŒåŸå§‹æ•°æ®å®Œæ•´æ€§
        schema_file_data = {
            "tool_name": tool_name,
            "schema": real_schema_data  # ä¿æŒåŸå§‹schemaæ•°æ®ä¸å˜
        }

        # ç”Ÿæˆæ–‡ä»¶åï¼šå·¥å…·åç§°.json
        output_file = tools_dir / f"{tool_name}.json"

        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(schema_file_data, f, ensure_ascii=False, indent=2)

        # éªŒè¯æ–‡ä»¶ä¿å­˜æˆåŠŸ
        if output_file.exists():
            file_size = output_file.stat().st_size
            print(f"   âœ… å·²ä¿å­˜: {output_file.name} ({file_size} bytes)")
        else:
            print(f"   âŒ ä¿å­˜å¤±è´¥: {output_file}")
            raise Exception(f"å·¥å…·schemaä¿å­˜å¤±è´¥: {tool_name}")

        print(f"âœ… end save_tool_schema(tool_name={tool_name}, output_dir={output_dir}) - success")
        return output_file
    except Exception as e:
        print(f"âŒ end save_tool_schema(tool_name={tool_name}, output_dir={output_dir}) - failed: {e}")
        raise


async def extract_single_tool_schema(tool_name, output_dir):
    """
    è·å–å•ä¸ªå·¥å…·çš„schemaå¹¶ä¿å­˜
    é›†æˆçœŸå®çš„MCPå·¥å…·è°ƒç”¨ï¼Œä¸ä½¿ç”¨mockæ•°æ®

    Args:
        tool_name: å·¥å…·åç§°
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„

    Returns:
        bool: æ˜¯å¦æˆåŠŸè·å–å¹¶ä¿å­˜
    """
    print(f"ğŸš€ begin extract_single_tool_schema(tool_name={tool_name}, output_dir={output_dir})")
    try:
        # 1. è°ƒç”¨ get_tool_schema() è·å–çœŸå®schemaæ•°æ®
        print(f"   ğŸ“¡ è°ƒç”¨MCPå·¥å…·è·å–schema...")
        schema_data = await get_tool_schema(tool_name)

        if not schema_data:
            print(f"   âŒ è·å–schemaå¤±è´¥: è¿”å›æ•°æ®ä¸ºç©º")
            return False

        print(f"   âœ… schemaæ•°æ®è·å–æˆåŠŸ:{str(schema_data)}")
        print(f"   ğŸ“Š æ•°æ®å¤§å°: {len(str(schema_data))} chars")

        # 2. è°ƒç”¨ save_tool_schema() ä¿å­˜åˆ°JSONæ–‡ä»¶
        print(f"   ğŸ’¾ ä¿å­˜schemaåˆ°æ–‡ä»¶...")
        saved_file = await save_tool_schema(tool_name, schema_data, output_dir)

        # 3. æˆåŠŸåè‡ªåŠ¨æ›´æ–°å·²å®Œæˆæ¸…å•
        print(f"   ğŸ“ æ›´æ–°å·²å®Œæˆæ¸…å•...")
        add_to_completed_list(tool_name, output_dir)

        print(f"   âœ… å·¥å…·schemaå¤„ç†å®Œæˆ: {tool_name}")
        print(f"âœ… end extract_single_tool_schema(tool_name={tool_name}, output_dir={output_dir}) - success")
        return True

    except Exception as e:
        print(f"   âŒ å·¥å…·schemaè·å–å¤±è´¥: {tool_name}")
        print(f"   ğŸ’¥ é”™è¯¯è¯¦æƒ…: {e}")
        print(f"âŒ end extract_single_tool_schema(tool_name={tool_name}, output_dir={output_dir}) - failed: {e}")
        return False


async def extract_all_schemas(tools, output_dir):
    """
    é€ä¸ªä¸²è¡Œè·å–æ‰€æœ‰å·¥å…·çš„schema
    å•çº¿ç¨‹æ‰§è¡Œï¼Œå¤±è´¥ç«‹å³åœæ­¢

    Args:
        tools: å·¥å…·åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    print(f"ğŸš€ begin extract_all_schemas(tools_count={len(tools)}, output_dir={output_dir})")
    try:
        # 1. è¯»å–å·²å®Œæˆæ¸…å•ï¼Œè·³è¿‡å·²å®Œæˆçš„å·¥å…·
        print(f"ğŸ“‹ æ£€æŸ¥å·²å®Œæˆçš„å·¥å…·...")
        completed_tools = load_completed_list(output_dir)

        # è·å–å¾…å¤„ç†çš„å·¥å…·åˆ—è¡¨
        pending_tools = [tool for tool in tools if tool not in completed_tools]

        print(f"ğŸ“Š è¿›åº¦çŠ¶æ€:")
        print(f"   æ€»å·¥å…·æ•°: {len(tools)}")
        print(f"   å·²å®Œæˆ: {len(completed_tools)}")
        print(f"   å¾…å¤„ç†: {len(pending_tools)}")
        print(f"   å®Œæˆç‡: {len(completed_tools)/len(tools)*100:.1f}%")

        if not pending_tools:
            print(f"ğŸ‰ æ‰€æœ‰å·¥å…·schemaå·²è·å–å®Œæˆï¼")
            print(f"âœ… end extract_all_schemas(tools_count={len(tools)}, output_dir={output_dir}) - success (all_completed)")
            return

        # 2. å•çº¿ç¨‹ä¸²è¡Œå¤„ç†å¾…å¤„ç†å·¥å…·
        print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡è·å–schema...")
        print(f"ğŸ“ å¤„ç†é¡ºåº: {pending_tools[:5]}{'...' if len(pending_tools) > 5 else ''}")

        success_count = 0
        failed_tool = None

        for i, tool_name in enumerate(pending_tools, 1):
            print(f"\nğŸ”§ [{i}/{len(pending_tools)}] å¤„ç†å·¥å…·: {tool_name}")
            print(f"   è¿›åº¦: {(len(completed_tools) + i - 1)/len(tools)*100:.1f}% â†’ {(len(completed_tools) + i)/len(tools)*100:.1f}%")

            # è°ƒç”¨å•ä¸ªå·¥å…·schemaè·å–å‡½æ•°
            success = await extract_single_tool_schema(tool_name, output_dir)

            if success:
                success_count += 1
                print(f"   âœ… æˆåŠŸ: {tool_name} ({success_count}/{len(pending_tools)})")
            else:
                # 3. å¤±è´¥æ—¶ç«‹å³åœæ­¢ï¼ˆfail-fastï¼‰
                failed_tool = tool_name
                print(f"   âŒ å¤±è´¥: {tool_name}")
                print(f"ğŸ’¥ æ‰¹é‡è·å–ä¸­æ–­ï¼Œfail-faståŸåˆ™")
                break

        # æœ€ç»ˆç»Ÿè®¡
        final_completed = load_completed_list(output_dir)
        final_completion_rate = len(final_completed)/len(tools)*100

        print(f"\nğŸ“Š æ‰¹é‡è·å–ç»“æœ:")
        print(f"   æœ¬æ¬¡å¤„ç†: {success_count}/{len(pending_tools)} æˆåŠŸ")
        print(f"   æ€»ä½“è¿›åº¦: {len(final_completed)}/{len(tools)} ({final_completion_rate:.1f}%)")

        if failed_tool:
            print(f"âŒ end extract_all_schemas(tools_count={len(tools)}, output_dir={output_dir}) - failed: {failed_tool}")
            raise Exception(f"å·¥å…·schemaè·å–å¤±è´¥: {failed_tool}")
        else:
            print(f"âœ… end extract_all_schemas(tools_count={len(tools)}, output_dir={output_dir}) - success (processed={success_count})")

    except Exception as e:
        print(f"âŒ end extract_all_schemas(tools_count={len(tools)}, output_dir={output_dir}) - failed: {e}")
        raise


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ K8s MCP å·¥å…·Schemaæå–è„šæœ¬")
    print("ğŸ“‹ å‡†å¤‡æå–55ä¸ªå·¥å…·çš„å®Œæ•´ä¿¡æ¯...")

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "schemas"

    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("âš ï¸  æ•°æ®å®Œæ•´æ€§åŸåˆ™: ç»å¯¹ä¸ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®")

    # æµ‹è¯•å·¥å…·åˆ—è¡¨æå–åŠŸèƒ½
    try:
        tools = await extract_tool_list()
        print(f"âœ… å·¥å…·åˆ—è¡¨æå–æˆåŠŸï¼Œå…± {len(tools)} ä¸ªå·¥å…·")

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å·¥å…·
        unique_tools = set(tools)
        if len(unique_tools) == len(tools):
            print("âœ… å·¥å…·åˆ—è¡¨æ— é‡å¤")
        else:
            print(f"âš ï¸ å‘ç°é‡å¤å·¥å…·: {len(tools) - len(unique_tools)} ä¸ª")

        # Task 2.2: ä¿å­˜å·¥å…·åˆ—è¡¨åˆ°JSONæ–‡ä»¶
        print("\nğŸ“‹ Task 2.2: ä¿å­˜å·¥å…·åˆ—è¡¨...")
        saved_file = save_tool_list(tools, output_dir)
        print(f"âœ… Task 2.2 å®Œæˆ: å·¥å…·åˆ—è¡¨å·²ä¿å­˜åˆ° {saved_file}")

        # æ‰¹é‡è·å–æ‰€æœ‰å·¥å…·çš„schema
        print("\nğŸ“‹ å¼€å§‹æ‰¹é‡è·å–æ‰€æœ‰å·¥å…·schema...")
        await extract_all_schemas(tools, output_dir)

        print(f"âœ… æ‰€æœ‰å·¥å…·schemaè·å–å®Œæˆ")

        return tools
    except Exception as e:
        print(f"âŒ å·¥å…·åˆ—è¡¨æå–å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
