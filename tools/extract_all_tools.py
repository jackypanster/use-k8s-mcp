#!/usr/bin/env python3
"""
K8s MCP å·¥å…·Schemaæå–è„šæœ¬
åŸºäº src/tool_discovery.pyï¼Œæå–æ‰€æœ‰55ä¸ªK8s MCPå·¥å…·çš„å®Œæ•´ä¿¡æ¯å¹¶ä¿å­˜ä¸ºJSONæ–‡ä»¶

æ ¸å¿ƒåŸåˆ™ï¼š
- ç»å¯¹ä¸è¦ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®
- ä¸¥æ ¼éµå¾ªå·¥å…·è¿”å›çš„åŸå§‹ç»“æœï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
- å•çº¿ç¨‹ä¸²è¡Œæ‰§è¡Œï¼Œfail-faståŸåˆ™
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"ğŸ”§ Pythonè·¯å¾„: {sys.path[0]}")

# å¯¼å…¥å·²éªŒè¯çš„å·¥å…·å‘ç°æ¨¡å—
from src.tool_discovery import get_tool_schema
from src.llm_config import create_llm
from dotenv import load_dotenv
from mcp_use import MCPAgent, MCPClient


async def extract_tool_list():
    """
    æå–æ‰€æœ‰K8s MCPå·¥å…·åˆ—è¡¨
    å¤ç”¨ src/tool_discovery.py ä¸­å·²éªŒè¯çš„é…ç½®
    """
    print("ğŸ“‹ å¼€å§‹è·å–å·¥å…·åˆ—è¡¨...")

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # å¤ç”¨å·²éªŒè¯çš„ MCP é…ç½®ï¼ˆæ—  type å­—æ®µï¼‰
    server_name = os.getenv("MCP_SERVER_NAME")
    server_url = os.getenv("MCP_SERVER_URL")

    mcp_config = {
        "mcpServers": {
            server_name: {
                "url": server_url
            }
        }
    }

    # åˆ›å»ºå·²éªŒè¯çš„ç»„ä»¶
    client = MCPClient.from_dict(mcp_config)
    llm = create_llm()
    agent = MCPAgent(llm=llm, client=client, max_steps=10)

    print(f"ğŸ”— MCPæœåŠ¡å™¨: {server_url}")

    # è·å–å·¥å…·åˆ—è¡¨ - ä½¿ç”¨ä¸ tool_discovery.py ç›¸åŒçš„ä¸¥æ ¼æŒ‡ä»¤
    tools_result = await agent.run(
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·åç§°ï¼Œåªè¿”å›å·¥å…·åç§°åˆ—è¡¨ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚
        ä¸¥æ ¼è¦æ±‚ï¼š
1. ç»å¯¹ä¸è¦ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®
2. ä¸¥æ ¼éµå¾ªå·¥å…·è¿”å›çš„åŸå§‹ç»“æœï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
3. åªå…è®¸å¯¹æ•°æ®è¿›è¡Œç»“æ„åŒ–è¾“å‡ºå’Œç¾åŒ–å±•ç¤º
4. ä¿ç•™æ‰€æœ‰å­—æ®µã€å€¼å’Œæ•°æ®ç»“æ„ï¼Œä¸å¾—çœç•¥ä»»ä½•ä¿¡æ¯
5. å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå¿…é¡»æ˜ç¡®æŠ¥å‘Šå¤±è´¥åŸå› ï¼Œä¸å¾—æä¾›ä»»ä½•æ¨¡æ‹Ÿæ•°æ®

ä½ çš„èŒè´£ä»…é™äºï¼šæ•°æ®æ ¼å¼åŒ–å’Œå¯è¯»æ€§ä¼˜åŒ–ï¼Œä¸¥ç¦ä»»ä½•å½¢å¼çš„æ•°æ®åˆ›é€ æˆ–ä¿®æ”¹ã€‚""",
        max_steps=5
    )

    print(f"ğŸ› ï¸ å·¥å…·åˆ—è¡¨åŸå§‹å“åº”é•¿åº¦: {len(tools_result)} chars")

    # è§£æå·¥å…·åˆ—è¡¨ - å¤ç”¨ tool_discovery.py çš„è§£æé€»è¾‘
    tool_names = []
    lines = tools_result.split('\n')
    for line in lines:
        line = line.strip()
        if line and not line.startswith('Thought:') and not line.startswith('Final Answer:'):
            # ç§»é™¤å¯èƒ½çš„åºå·å’Œç‰¹æ®Šå­—ç¬¦
            clean_line = line.replace('*', '').replace('-', '').replace('â€¢', '').strip()
            if clean_line and len(clean_line) > 2:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
                tool_names.append(clean_line)

    print(f"ğŸ“Š è§£æå‡º {len(tool_names)} ä¸ªå·¥å…·åç§°")

    # æ˜¾ç¤ºå‰5ä¸ªå·¥å…·ä½œä¸ºéªŒè¯
    for i, tool in enumerate(tool_names[:5]):
        print(f"   {i+1}. {tool}")
    if len(tool_names) > 5:
        print(f"   ... è¿˜æœ‰ {len(tool_names) - 5} ä¸ªå·¥å…·")

    return tool_names


def save_tool_list(tools, output_dir):
    """
    ä¿å­˜å·¥å…·åˆ—è¡¨åˆ°JSONæ–‡ä»¶

    Args:
        tools: å·¥å…·åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    print("ğŸ’¾ å¼€å§‹ä¿å­˜å·¥å…·åˆ—è¡¨...")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ„å»ºå·¥å…·åˆ—è¡¨æ•°æ®ç»“æ„
    tool_list_data = {
        "total_count": len(tools),
        "extraction_timestamp": "2025-06-20",
        "data_integrity_principle": "ç»å¯¹ä¸ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®",
        "tools": tools
    }

    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    output_file = output_dir / "tool_list.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(tool_list_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… å·¥å…·åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š åŒ…å« {len(tools)} ä¸ªå·¥å…·åç§°")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_file.stat().st_size} bytes")

    return output_file


def verify_tool_list_completeness(tools, output_file):
    """
    éªŒè¯å·¥å…·åˆ—è¡¨å®Œæ•´æ€§

    Args:
        tools: å·¥å…·åç§°åˆ—è¡¨
        output_file: ä¿å­˜çš„JSONæ–‡ä»¶è·¯å¾„

    Returns:
        bool: éªŒè¯æ˜¯å¦é€šè¿‡
    """
    print("\nğŸ” Task 2.3: éªŒè¯å·¥å…·åˆ—è¡¨å®Œæ•´æ€§...")

    verification_passed = True

    # éªŒæ”¶æ ‡å‡†1: å·¥å…·æ•°é‡ = 55
    print(f"ğŸ“Š éªŒè¯å·¥å…·æ•°é‡...")
    expected_count = 55
    actual_count = len(tools)
    if actual_count == expected_count:
        print(f"   âœ… å·¥å…·æ•°é‡æ­£ç¡®: {actual_count}/{expected_count}")
    else:
        print(f"   âŒ å·¥å…·æ•°é‡ä¸ç¬¦: {actual_count}/{expected_count}")
        verification_passed = False

    # éªŒæ”¶æ ‡å‡†2: åŒ…å«å·²çŸ¥æ ¸å¿ƒå·¥å…·
    print(f"ğŸ” éªŒè¯æ ¸å¿ƒå·¥å…·...")
    core_tools = ["LIST_CLUSTERS", "GET_CLUSTER_INFO", "LIST_NAMESPACES", "LIST_NODES"]
    found_core_tools = []
    missing_core_tools = []

    for core_tool in core_tools:
        if core_tool in tools:
            found_core_tools.append(core_tool)
            print(f"   âœ… {core_tool}")
        else:
            missing_core_tools.append(core_tool)
            print(f"   âŒ {core_tool} - ç¼ºå¤±")
            verification_passed = False

    print(f"ğŸ“ˆ æ ¸å¿ƒå·¥å…·è¦†ç›–ç‡: {len(found_core_tools)}/{len(core_tools)} ({len(found_core_tools)/len(core_tools)*100:.1f}%)")

    # éªŒæ”¶æ ‡å‡†3: å·¥å…·åç§°æ— é‡å¤
    print(f"ğŸ”„ éªŒè¯é‡å¤å·¥å…·...")
    unique_tools = set(tools)
    duplicate_count = len(tools) - len(unique_tools)
    if duplicate_count == 0:
        print(f"   âœ… å·¥å…·åˆ—è¡¨æ— é‡å¤")
    else:
        print(f"   âŒ å‘ç°é‡å¤å·¥å…·: {duplicate_count} ä¸ª")
        verification_passed = False

        # æ‰¾å‡ºé‡å¤çš„å·¥å…·
        seen = set()
        duplicates = set()
        for tool in tools:
            if tool in seen:
                duplicates.add(tool)
            else:
                seen.add(tool)
        print(f"   é‡å¤å·¥å…·: {list(duplicates)}")

    # éªŒè¯JSONæ–‡ä»¶
    print(f"ğŸ“ éªŒè¯JSONæ–‡ä»¶...")
    if output_file.exists():
        file_size = output_file.stat().st_size
        print(f"   âœ… æ–‡ä»¶å­˜åœ¨: {output_file}")
        print(f"   âœ… æ–‡ä»¶å¤§å°: {file_size} bytes")

        # éªŒè¯JSONæ ¼å¼
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"   âœ… JSONæ ¼å¼æ­£ç¡®")

            # éªŒè¯JSONå†…å®¹
            if 'tools' in data and len(data['tools']) == len(tools):
                print(f"   âœ… JSONå†…å®¹å®Œæ•´")
            else:
                print(f"   âŒ JSONå†…å®¹ä¸å®Œæ•´")
                verification_passed = False

        except json.JSONDecodeError as e:
            print(f"   âŒ JSONæ ¼å¼é”™è¯¯: {e}")
            verification_passed = False
    else:
        print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {output_file}")
        verification_passed = False

    # æ€»ç»“éªŒè¯ç»“æœ
    print(f"\nğŸ“‹ Task 2.3 éªŒè¯ç»“æœ:")
    if verification_passed:
        print(f"   âœ… æ‰€æœ‰éªŒæ”¶æ ‡å‡†é€šè¿‡")
        print(f"   âœ… å·¥å…·åˆ—è¡¨å®Œæ•´æ€§éªŒè¯æˆåŠŸ")
    else:
        print(f"   âŒ éƒ¨åˆ†éªŒæ”¶æ ‡å‡†æœªé€šè¿‡")
        print(f"   âŒ å·¥å…·åˆ—è¡¨å®Œæ•´æ€§éªŒè¯å¤±è´¥")

    return verification_passed


async def save_tool_schema(tool_name, schema_data, output_dir):
    """
    ä¿å­˜å•ä¸ªå·¥å…·çš„schemaåˆ°JSONæ–‡ä»¶

    Args:
        tool_name: å·¥å…·åç§°
        schema_data: schemaåŸå§‹æ•°æ®
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    # TODO: å®ç°å•ä¸ªå·¥å…·schemaä¿å­˜é€»è¾‘
    pass


async def extract_all_schemas(tools, output_dir):
    """
    é€ä¸ªä¸²è¡Œè·å–æ‰€æœ‰å·¥å…·çš„schema
    å•çº¿ç¨‹æ‰§è¡Œï¼Œå¤±è´¥ç«‹å³åœæ­¢

    Args:
        tools: å·¥å…·åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    # TODO: å®ç°æ‰¹é‡schemaæå–é€»è¾‘
    pass


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ K8s MCP å·¥å…·Schemaæå–è„šæœ¬")
    print("ğŸ“‹ å‡†å¤‡æå–55ä¸ªå·¥å…·çš„å®Œæ•´ä¿¡æ¯...")

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "schemas"

    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("âš ï¸  æ•°æ®å®Œæ•´æ€§åŸåˆ™: ç»å¯¹ä¸ç¼–é€ ã€ä¿®æ”¹ã€åˆ å‡æˆ–å‹ç¼©ä»»ä½•è¿”å›æ•°æ®")

    # æµ‹è¯•å·¥å…·åˆ—è¡¨æå–åŠŸèƒ½
    try:
        tools = await extract_tool_list()
        print(f"âœ… å·¥å…·åˆ—è¡¨æå–æˆåŠŸï¼Œå…± {len(tools)} ä¸ªå·¥å…·")

        # éªŒè¯æ˜¯å¦åŒ…å«å·²çŸ¥çš„æ ¸å¿ƒå·¥å…·
        core_tools = ["LIST_CLUSTERS", "GET_CLUSTER_INFO", "LIST_NAMESPACES", "LIST_NODES"]
        found_core_tools = [tool for tool in core_tools if tool in tools]
        print(f"ğŸ” æ ¸å¿ƒå·¥å…·éªŒè¯: æ‰¾åˆ° {len(found_core_tools)}/{len(core_tools)} ä¸ªæ ¸å¿ƒå·¥å…·")
        for tool in found_core_tools:
            print(f"   âœ… {tool}")

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å·¥å…·
        unique_tools = set(tools)
        if len(unique_tools) == len(tools):
            print("âœ… å·¥å…·åˆ—è¡¨æ— é‡å¤")
        else:
            print(f"âš ï¸ å‘ç°é‡å¤å·¥å…·: {len(tools) - len(unique_tools)} ä¸ª")

        # Task 2.2: ä¿å­˜å·¥å…·åˆ—è¡¨åˆ°JSONæ–‡ä»¶
        print("\nğŸ“‹ Task 2.2: ä¿å­˜å·¥å…·åˆ—è¡¨...")
        saved_file = save_tool_list(tools, output_dir)
        print(f"âœ… Task 2.2 å®Œæˆ: å·¥å…·åˆ—è¡¨å·²ä¿å­˜åˆ° {saved_file}")

        # Task 2.3: éªŒè¯å·¥å…·åˆ—è¡¨å®Œæ•´æ€§
        verification_passed = verify_tool_list_completeness(tools, saved_file)
        if verification_passed:
            print(f"âœ… Task 2.3 å®Œæˆ: å·¥å…·åˆ—è¡¨å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            print(f"âŒ Task 2.3 å¤±è´¥: å·¥å…·åˆ—è¡¨å®Œæ•´æ€§éªŒè¯æœªé€šè¿‡")
            raise Exception("å·¥å…·åˆ—è¡¨å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")

        return tools
    except Exception as e:
        print(f"âŒ å·¥å…·åˆ—è¡¨æå–å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
